{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9f1cfd-042b-4916-b84e-10a40ee621d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from composio import Composio  # type: ignore\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d81ce6-6697-47f2-9d0a-e52fecea5763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(Path(\"../../../../.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22f99eb-e4dd-4731-a9ec-0b97732fcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example tool function\n",
    "def get_weather(location: str) -> str:\n",
    "    # Here you would implement actual weather lookup logic\n",
    "    return f\"The current temperature in {location} is 72Â°F.\"\n",
    "\n",
    "\n",
    "# Define your tools schema like your snippet\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City and country e.g. BogotÃ¡, Colombia\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "        \"strict\": True,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e86adf-a730-48e1-8b4e-c55c007c452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for planner agent\n",
    "CHATBOT_PROMPT = \"\"\"\n",
    "You are an expert AI assistant. \n",
    "\n",
    "\n",
    "You take in a prompt from a user and respond to it directly with your personal knowledge.\n",
    "Or you use tools given to you to get live information and genereate a response using the results of the tools.\n",
    "\n",
    "CORE PRINCIPLE: Be direct, concise and . Minimize follow-up questions.\n",
    "You MUST effectively communicate the topic in a clear and engaging manner.\n",
    "\n",
    "DEFAULT ASSUMPTIONS FOR REQUESTS:\n",
    "- Promopts can be about anything\n",
    "- The promopt might be vague or unclear, one word, or unclear intent\n",
    "- The request might be very specific or clear\n",
    "\n",
    "\n",
    "IMMEDIATE PLANNING APPROACH:\n",
    "**WORKFLOW:**\n",
    "1. Respond directly if you have personal knowledge about the topic\n",
    "2. Use tools to get live information on the topic and then generate a response\n",
    "3. If you require a tool call or several. ALWAYS RESPOND WITH TEXT ALONG WITH A TOOL CALL. This will let the user know what is going on.\n",
    "4. Use tools APPROPRIATELY\n",
    "\n",
    "SAMPLE RESPONSE FOR ANSWERING A PROMPT WITH PERSONAL KNOWLEDGE (NOT LIMITED TO ONLY THESE STEPS)\n",
    "Get user message\n",
    "Simply respond directly\n",
    "\n",
    "\n",
    "SAMPLE RESPONSE FOR ANSWERING A PROMPT WITH TOOLS (NOT LIMITED TO ONLY THESE STEPS)\n",
    "Get user message\n",
    "IF message contains words like today, recent, current, live or other words with similar meaning then use tools to get live information on the message and then generate a response\n",
    "Call tool or several tools\n",
    "Use tool results to generate a response\n",
    "\n",
    "\n",
    "\n",
    "TOOL CALLING STRATEGY:\n",
    "- YOU MUST ALWAYS RESPOND WITH TEXT ALONG WITH A TOOL CALL\n",
    "- THIS WILL LET THE USER KNOW WHAT IS GOING ON\n",
    "- FAILURE TO RESPOND WITH A TEXT AND A TOOL CALL WILLRESULT IN FAILURE\n",
    "- AVOID repetative tool calls\n",
    "- ONLY USE TOOLS IF message contains words like today, recent, current, live or other words with similar meaning\n",
    "\n",
    "MINIMAL QUESTIONS STRATEGY:\n",
    "- For vauge requests such as single words: generate an interesting topic ie: star wars -> star wars impact on modern culture, then plan and create tasks\n",
    "- For detailed requests: Create multiple tasks \n",
    "\n",
    "\n",
    "Generate text response and tool calls (if applicable) withput asking follow-up questions unless absolutely necessary.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51ad287-e00c-4b09-b342-5405a279b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        self.chat_history: list[dict] = []\n",
    "        self.llm: OpenAI = None\n",
    "        self.tools = tools\n",
    "        self.tool_functions = {\"get_weather\": get_weather}\n",
    "        self.model_name: str = \"gpt-4.1-mini\"\n",
    "        self.composio = Composio()\n",
    "        self.user_id = \"0000-1111-2222\"\n",
    "        self.previous_task_results: list[dict] = [\n",
    "            {\n",
    "                \"task_id\": \"0\",\n",
    "                \"task\": \"first task, no previous task yet\",\n",
    "                \"results\": \"first task, no results yet\",\n",
    "            }\n",
    "        ]\n",
    "        pass\n",
    "\n",
    "    def init_chat_services(self):\n",
    "        self.add_chat_history(role=\"developer\", message=CHATBOT_PROMPT)\n",
    "\n",
    "    def add_chat_history(self, role: str, message: str):\n",
    "        self.chat_history.append({\"role\": role, \"content\": message})\n",
    "\n",
    "    def call_function(self, name, args):\n",
    "        if name == \"get_weather\":\n",
    "            res = get_weather(args[\"location\"])\n",
    "            return res\n",
    "\n",
    "    def process_message(self, message):\n",
    "        self.add_chat_history(role=\"user\", message=message)\n",
    "        print(f\"process_message called with message: {message}\")  # DEBUG\n",
    "\n",
    "        stream = self.llm.responses.create(\n",
    "            model=self.model_name,\n",
    "            input=self.chat_history,\n",
    "            tools=self.tools,\n",
    "            tool_choice=\"auto\",\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        assistant_text = \"\"\n",
    "        tool_call = None\n",
    "\n",
    "        print(\"Starting LLM stream\")\n",
    "        for event in stream:\n",
    "            print(f\"Received event: {event}\")\n",
    "\n",
    "            # Check if event has a direct 'delta' attribute (like ResponseTextDeltaEvent)\n",
    "            if hasattr(event, \"delta\"):\n",
    "                # 'delta' could be a string chunk or dict; handle both\n",
    "                delta_content = event.delta\n",
    "                if isinstance(delta_content, str):\n",
    "                    content = delta_content\n",
    "                elif isinstance(delta_content, dict):\n",
    "                    # If dict, extract 'content' field safely\n",
    "                    content = delta_content.get(\"content\", \"\")\n",
    "                else:\n",
    "                    content = \"\"\n",
    "\n",
    "                assistant_text += content\n",
    "                yield content\n",
    "                continue\n",
    "\n",
    "            for tool_call in event.output:\n",
    "                if tool_call.type != \"function_call\":\n",
    "                    continue\n",
    "                # select tool name\n",
    "                tool_name = tool_call.name\n",
    "                # get the arguments for the tool\n",
    "                tool_args = json.loads(tool_call.arguments)\n",
    "\n",
    "                # call the function\n",
    "                if tool_name == \"get_weather\":\n",
    "                    # call the function\n",
    "                    result = self.call_function(tool_name, tool_args)\n",
    "\n",
    "                    # Add tool result to chat history\n",
    "                    self.add_chat_history(\n",
    "                        role=\"system\",\n",
    "                        message=f\"Tool {tool_name} returned: {result}\",\n",
    "                    )\n",
    "\n",
    "                    stream2 = self.llm.responses.stream(\n",
    "                        model=self.model_name,\n",
    "                        input=self.chat_history,\n",
    "                    )\n",
    "\n",
    "                    assistant_text = \"\"\n",
    "                    for event in stream2:\n",
    "                        print(f\"Received event: {event}\")\n",
    "\n",
    "                        # Check if event has a direct 'delta' attribute (like ResponseTextDeltaEvent)\n",
    "                        if hasattr(event, \"delta\"):\n",
    "                            # 'delta' could be a string chunk or dict; handle both\n",
    "                            delta_content = event.delta\n",
    "                            if isinstance(delta_content, str):\n",
    "                                content = delta_content\n",
    "                            elif isinstance(delta_content, dict):\n",
    "                                # If dict, extract 'content' field safely\n",
    "                                content = delta_content.get(\"content\", \"\")\n",
    "                            else:\n",
    "                                content = \"\"\n",
    "\n",
    "                            assistant_text += content\n",
    "                            yield content\n",
    "                            continue\n",
    "\n",
    "                    self.add_chat_history(\"assistant\", assistant_text)\n",
    "\n",
    "                    return\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        print(self.chat_history)\n",
    "\n",
    "        # If no tool call, add full assistant response after stream ends\n",
    "        if not tool_call:\n",
    "            self.add_chat_history(\"assistant\", assistant_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f86ee20-b1b0-45ab-9002-3a5b0d4192f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_bot = ChatService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "389d6238-5dd2-4582-96e5-0b5689d38cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(message):\n",
    "    try:\n",
    "        for chunk in chat_bot.process_message(message):\n",
    "            print(f\"Yielding chunk: {chunk}\")  # DEBUG\n",
    "            yield f\"data: {chunk}\\n\\n\"\n",
    "            sys.stdout.flush()  # ðŸ”¹ flush after each yield\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in generate_response: {e}\")\n",
    "        yield f\"data: [Error] {str(e)}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae571c5c-5da3-464d-a782-9fe5dccd54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = generate_response('What is the weather in San Francisco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f277c42-e2d0-45b6-bd1d-d8e7a2f82d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__class_getitem__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'close',\n",
       " 'gi_code',\n",
       " 'gi_frame',\n",
       " 'gi_running',\n",
       " 'gi_suspended',\n",
       " 'gi_yieldfrom',\n",
       " 'send',\n",
       " 'throw']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb3f84e7-e320-4056-bb27-9e73b322f6da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mf_res\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'f_res' is not defined"
     ]
    }
   ],
   "source": [
    "f_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d43b950-15da-463c-ad81-7c6f3c422881",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stream = \u001b[38;5;28;43mself\u001b[39;49m.llm.responses.create(\n\u001b[32m      2\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model_name,\n\u001b[32m      3\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28mself\u001b[39m.chat_history,\n\u001b[32m      4\u001b[39m     tools=\u001b[38;5;28mself\u001b[39m.tools,\n\u001b[32m      5\u001b[39m     tool_choice=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m assistant_text = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m tool_call = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "        stream = self.llm.responses.create(\n",
    "            model=self.model_name,\n",
    "            input=self.chat_history,\n",
    "            tools=self.tools,\n",
    "            tool_choice=\"auto\",\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        assistant_text = \"\"\n",
    "        tool_call = None\n",
    "\n",
    "        print(\"Starting LLM stream\")\n",
    "        for event in stream:\n",
    "            print(f\"Received event: {event}\")\n",
    "\n",
    "            # Check if event has a direct 'delta' attribute (like ResponseTextDeltaEvent)\n",
    "            if hasattr(event, \"delta\"):\n",
    "                # 'delta' could be a string chunk or dict; handle both\n",
    "                delta_content = event.delta\n",
    "                if isinstance(delta_content, str):\n",
    "                    content = delta_content\n",
    "                elif isinstance(delta_content, dict):\n",
    "                    # If dict, extract 'content' field safely\n",
    "                    content = delta_content.get(\"content\", \"\")\n",
    "                else:\n",
    "                    content = \"\"\n",
    "\n",
    "                assistant_text += content\n",
    "                yield content\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70adaf6c-85f1-4331-85b8-ce7814e24b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "939a14b0-5d9b-4017-be5b-7e60e32487a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [{'role': \"developer\", 'content': 'do whatever the user says'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808ec68-e022-44ab-9454-f4cf64928317",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append({'role': 'user', 'content': 'Say 'double bubble bath' ten times fast.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "568c8c3b-da08-4a02-8ea0-3fe47ee343a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT: ResponseCreatedEvent(response=Response(id='resp_689bb5b8294c81908f8c703cf87f515a0adbdc3bb28298f2', created_at=1755035064.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'response', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_created_event.ResponseCreatedEvent'>\n",
      "EVENT: ResponseInProgressEvent(response=Response(id='resp_689bb5b8294c81908f8c703cf87f515a0adbdc3bb28298f2', created_at=1755035064.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'response', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_in_progress_event.ResponseInProgressEvent'>\n",
      "EVENT: ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', content=[], role='assistant', status='in_progress', type='message'), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'item', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_output_item_added_event.ResponseOutputItemAddedEvent'>\n",
      "EVENT: ResponseContentPartAddedEvent(content_index=0, item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=3, type='response.content_part.added')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'dict', 'from_orm', 'item_id', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'part', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_content_part_added_event.ResponseContentPartAddedEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta='Under', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta', obfuscation='P8RMV266xwQ')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta='stood', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta', obfuscation='0OWdDuok4kM')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta', obfuscation='3NFHUICaWj16LBB')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta=' How', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=7, type='response.output_text.delta', obfuscation='5SPbn2BN3qYN')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta=' can', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=8, type='response.output_text.delta', obfuscation='cXC6cSKtSHEF')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta=' I', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=9, type='response.output_text.delta', obfuscation='FSpmfVdB7dhkyX')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta=' assist', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=10, type='response.output_text.delta', obfuscation='0fPzNHccM')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta=' you', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=11, type='response.output_text.delta', obfuscation='NFXA3rEPAWjR')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta=' today', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=12, type='response.output_text.delta', obfuscation='0kjFkKVBxz')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDeltaEvent(content_index=0, delta='?', item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=13, type='response.output_text.delta', obfuscation='abboFy6bmHEqE2j')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'delta', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_delta_event.ResponseTextDeltaEvent'>\n",
      "EVENT: ResponseTextDoneEvent(content_index=0, item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', logprobs=[], output_index=0, sequence_number=14, text='Understood! How can I assist you today?', type='response.output_text.done')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'dict', 'from_orm', 'item_id', 'json', 'logprobs', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'text', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_text_done_event.ResponseTextDoneEvent'>\n",
      "EVENT: ResponseContentPartDoneEvent(content_index=0, item_id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', output_index=0, part=ResponseOutputText(annotations=[], text='Understood! How can I assist you today?', type='output_text', logprobs=[]), sequence_number=15, type='response.content_part.done')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content_index', 'copy', 'dict', 'from_orm', 'item_id', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'part', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_content_part_done_event.ResponseContentPartDoneEvent'>\n",
      "EVENT: ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', content=[ResponseOutputText(annotations=[], text='Understood! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), output_index=0, sequence_number=16, type='response.output_item.done')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'item', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_index', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_output_item_done_event.ResponseOutputItemDoneEvent'>\n",
      "EVENT: ResponseCompletedEvent(response=Response(id='resp_689bb5b8294c81908f8c703cf87f515a0adbdc3bb28298f2', created_at=1755035064.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_689bb5b8b5208190810434ccee3ee2180adbdc3bb28298f2', content=[ResponseOutputText(annotations=[], text='Understood! How can I assist you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=12, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=11, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=23), user=None, store=True), sequence_number=17, type='response.completed')\n",
      "EVENT: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__firstlineno__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'copy', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'response', 'schema', 'schema_json', 'sequence_number', 'to_dict', 'to_json', 'type', 'update_forward_refs', 'validate']\n",
      "EVENT TYPE: <class 'openai.types.responses.response_completed_event.ResponseCompletedEvent'>\n"
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=chat_history,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(f'EVENT: {event}')\n",
    "    print(f'EVENT: {dir(event)}')\n",
    "    print(f'EVENT TYPE: {type(event)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c854e0ec-fa04-445f-bd12-1630acc81619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__static_attributes__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_decoder',\n",
       " '_elapsed',\n",
       " '_get_content_decoder',\n",
       " '_num_bytes_downloaded',\n",
       " '_prepare',\n",
       " '_request',\n",
       " 'aclose',\n",
       " 'aiter_bytes',\n",
       " 'aiter_lines',\n",
       " 'aiter_raw',\n",
       " 'aiter_text',\n",
       " 'aread',\n",
       " 'charset_encoding',\n",
       " 'close',\n",
       " 'content',\n",
       " 'cookies',\n",
       " 'default_encoding',\n",
       " 'elapsed',\n",
       " 'encoding',\n",
       " 'extensions',\n",
       " 'has_redirect_location',\n",
       " 'headers',\n",
       " 'history',\n",
       " 'http_version',\n",
       " 'is_client_error',\n",
       " 'is_closed',\n",
       " 'is_error',\n",
       " 'is_informational',\n",
       " 'is_redirect',\n",
       " 'is_server_error',\n",
       " 'is_stream_consumed',\n",
       " 'is_success',\n",
       " 'iter_bytes',\n",
       " 'iter_lines',\n",
       " 'iter_raw',\n",
       " 'iter_text',\n",
       " 'json',\n",
       " 'links',\n",
       " 'next_request',\n",
       " 'num_bytes_downloaded',\n",
       " 'raise_for_status',\n",
       " 'read',\n",
       " 'reason_phrase',\n",
       " 'request',\n",
       " 'status_code',\n",
       " 'stream',\n",
       " 'text',\n",
       " 'url']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(stream.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6dbef13-4bb6-40ed-956b-d28ada9304d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [{'role': \"developer\", 'content': 'You are an assistant tasked with helping the user'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "55292b6a-0950-4863-8b9f-e20628812cb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat_historya' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchat_historya\u001b[49m.append({\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mwhat is the current weather in san francisco\u001b[39m\u001b[33m'\u001b[39m})\n",
      "\u001b[31mNameError\u001b[39m: name 'chat_historya' is not defined"
     ]
    }
   ],
   "source": [
    "chat_history.append({'role': \"user\", 'content': 'what is the current weather in san francisco'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b31064f-04c8-4a7f-9616-663e90d5eebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n",
      " double\n",
      " bubble\n",
      " bath\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say 'double bubble bath' ten times fast.\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "full_text = ''\n",
    "for event in stream:\n",
    "    if hasattr(event, \"delta\"):\n",
    "        print(event.delta)\n",
    "        full_text += event.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a216d18-9f43-41ae-ac24-bafb2fd5585b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'double bubble bath double bubble bath double bubble bath double bubble bath double bubble bath double bubble bath double bubble bath double bubble bath double bubble bath double bubble bath'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64480207-8279-4bd1-bbbd-6e5ed948555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append({'role': 'user', 'content': 'what is the weather in sf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe7b18c8-df2a-4123-ba24-4f3a9f68e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8fe79840-84b8-43b5-9af5-6be36a250c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitResponse(BaseModel):\n",
    "    thought: str = Field(\n",
    "        description=\"Given the user input what needs to be done and how\",\n",
    "    )\n",
    "    more_info: bool = Field(description='If we need more information to answer something')\n",
    "    response: str = Field(description='The response if we dont need more information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "101fb401-74cf-4e43-adb7-d54f17c4bb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf768bb1-37c2-4239-ad52-78e39e2eb576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542eb7d8-7319-44b0-9c66-c0553ee53e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntitiesModel(BaseModel):\n",
    "    attributes: List[str]\n",
    "    colors: List[str]\n",
    "    animals: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e62000a3-8bbc-49e7-8cbc-d67b9f60e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_HANDLERS = {\n",
    "    \"get_weather\": get_weather,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3828a840-389a-42ef-99a7-ae7352c7610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_execute_tool(output_index):\n",
    "    \"\"\"\n",
    "    Called when we have final_tool_calls[output_index]['done'] == True.\n",
    "    Parses args, runs the tool, appends tool result to chat_history and streams final answer.\n",
    "    \"\"\"\n",
    "    entry = final_tool_calls.get(output_index)\n",
    "    if not entry:\n",
    "        print(f\"[DEBUG] No entry found for output_index={output_index}\")\n",
    "        return\n",
    "\n",
    "    tool_name = entry.get(\"name\")\n",
    "    args_str = entry.get(\"arguments\", \"\")\n",
    "    print(f\"[DEBUG] Processing tool call at index={output_index}: name={tool_name}, raw_args={args_str}\")\n",
    "\n",
    "    # Fallback to single tool if name wasn't sent\n",
    "    if not tool_name:\n",
    "        if len(tools) == 1 and \"name\" in tools[0]:\n",
    "            tool_name = tools[0][\"name\"]\n",
    "            print(f\"[DEBUG] No tool name in stream; falling back to single provided tool: {tool_name}\")\n",
    "        else:\n",
    "            print(\"[DEBUG] No tool name and multiple/no tools available â€” cannot execute safely.\")\n",
    "            return\n",
    "\n",
    "    try:\n",
    "        parsed_args = json.loads(args_str or \"{}\")\n",
    "    except json.JSONDecodeError:\n",
    "        parsed_args = {}\n",
    "        print(\"[DEBUG] Failed to parse JSON args; using empty dict\")\n",
    "\n",
    "    print(f\"[DEBUG] Parsed args for {tool_name}: {parsed_args}\")\n",
    "\n",
    "    handler = TOOL_HANDLERS.get(tool_name)\n",
    "    if not handler:\n",
    "        print(f\"[DEBUG] No local handler for tool '{tool_name}'\")\n",
    "        return\n",
    "\n",
    "    # Execute the tool\n",
    "    try:\n",
    "        # adapt call depending on expected signature\n",
    "        tool_result = handler(**parsed_args) if isinstance(parsed_args, dict) else handler(parsed_args)\n",
    "    except TypeError:\n",
    "        # fallback if handler expects single positional arg\n",
    "        tool_result = handler(parsed_args.get(\"location\") if isinstance(parsed_args, dict) else parsed_args)\n",
    "\n",
    "    print(f\"[DEBUG] Tool result: {tool_result}\")\n",
    "\n",
    "    # Append tool output for the model to consume\n",
    "    chat_history.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f'TOOL_NAME: {tool_name}, RESULT: {tool_result}'\n",
    "    })\n",
    "\n",
    "    # Re-call the model to get its final answer (streamed)\n",
    "    print(\"[DEBUG] Re-calling model to get final answer after tool execution...\")\n",
    "    final_stream = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=chat_history,\n",
    "        tools=tools,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    print(\"Assistant (final): \", end=\"\", flush=True)\n",
    "    for ev in final_stream:\n",
    "        print(f\"\\n[DEBUG EVENT FINAL] type={ev.type}, delta={getattr(ev, 'delta', None)}\")\n",
    "        if ev.type == \"response.output_text.delta\":\n",
    "            print(ev.delta, end=\"\", flush=True)\n",
    "        elif ev.type == \"response.output_text.done\":\n",
    "            print()  # newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15b6413a-7c4d-467a-a29b-5d7af5b9d49b",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid value: 'tool'. Supported values are: 'assistant', 'system', 'developer', and 'user'.\", 'type': 'invalid_request_error', 'param': 'input[2]', 'code': 'invalid_value'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stream = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m final_tool_calls = {}  \u001b[38;5;66;03m# output_index -> {\"item\": ..., \"name\": None, \"arguments\": \"\", \"done\": False}\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Main streaming loop: aggregate and trigger processing when arguments are done\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/rag/backend/.venv/lib/python3.13/site-packages/openai/resources/responses/responses.py:795\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    760\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    761\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    794\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/rag/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/rag/backend/.venv/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid value: 'tool'. Supported values are: 'assistant', 'system', 'developer', and 'user'.\", 'type': 'invalid_request_error', 'param': 'input[2]', 'code': 'invalid_value'}}"
     ]
    }
   ],
   "source": [
    "stream = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=chat_history,\n",
    "    tools=tools,\n",
    "    stream=True)\n",
    "final_tool_calls = {}  # output_index -> {\"item\": ..., \"name\": None, \"arguments\": \"\", \"done\": False}\n",
    "# Main streaming loop: aggregate and trigger processing when arguments are done\n",
    "for event in stream:\n",
    "    # show the raw event for debugging\n",
    "    print(f\"\\n[DEBUG EVENT] type={event.type}, output_index={getattr(event, 'output_index', None)}, delta={getattr(event, 'delta', None)}\")\n",
    "\n",
    "    # Normal text streaming\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "\n",
    "    elif event.type == \"response.output_text.done\":\n",
    "        print()\n",
    "\n",
    "    # When an output item is added, initialize storage for it\n",
    "    elif event.type == \"response.output_item.added\":\n",
    "        idx = getattr(event, \"output_index\", 0)\n",
    "        final_tool_calls[idx] = {\n",
    "            \"item\": getattr(event, \"item\", None),\n",
    "            \"name\": None,\n",
    "            \"arguments\": \"\",\n",
    "            \"done\": False\n",
    "        }\n",
    "        print(f\"[DEBUG] output_item.added -> initialized final_tool_calls[{idx}]\")\n",
    "\n",
    "    # Some streams send name under function_call.delta or tool_call.delta\n",
    "    elif event.type in (\"response.function_call.delta\", \"response.tool_call.delta\"):\n",
    "        idx = getattr(event, \"output_index\", 0)\n",
    "        # ensure slot exists\n",
    "        if idx not in final_tool_calls:\n",
    "            final_tool_calls[idx] = {\"item\": None, \"name\": None, \"arguments\": \"\", \"done\": False}\n",
    "        # sometimes delta is a dict with \"name\"\n",
    "        delta = getattr(event, \"delta\", None)\n",
    "        if isinstance(delta, dict) and \"name\" in delta:\n",
    "            final_tool_calls[idx][\"name\"] = delta[\"name\"]\n",
    "            print(f\"[DEBUG] Captured function/tool name for index={idx}: {delta['name']}\")\n",
    "\n",
    "    # Arguments come token-by-token as strings\n",
    "    elif event.type == \"response.function_call_arguments.delta\":\n",
    "        idx = getattr(event, \"output_index\", 0)\n",
    "        if idx not in final_tool_calls:\n",
    "            final_tool_calls[idx] = {\"item\": None, \"name\": None, \"arguments\": \"\", \"done\": False}\n",
    "        # delta may be a string fragment\n",
    "        frag = event.delta if not isinstance(event.delta, dict) else json.dumps(event.delta)\n",
    "        final_tool_calls[idx][\"arguments\"] += frag\n",
    "        print(f\"[DEBUG] Appended arg fragment to index={idx}: {frag}\")\n",
    "\n",
    "    elif event.type == \"response.function_call_arguments.done\":\n",
    "        idx = getattr(event, \"output_index\", 0)\n",
    "        if idx not in final_tool_calls:\n",
    "            final_tool_calls[idx] = {\"item\": None, \"name\": None, \"arguments\": \"\", \"done\": False}\n",
    "        final_tool_calls[idx][\"done\"] = True\n",
    "        print(f\"[DEBUG] function_call_arguments.done for index={idx}. full_args={final_tool_calls[idx]['arguments']}\")\n",
    "\n",
    "        # process this particular tool call immediately\n",
    "        process_and_execute_tool(idx)\n",
    "        \n",
    "# after stream finished, show what we collected\n",
    "print(\"\\n[DEBUG] final_tool_calls dump:\")\n",
    "for idx, v in final_tool_calls.items():\n",
    "    print(f\"  index={idx}: name={v.get('name')}, done={v.get('done')}, args={v.get('arguments')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f085d0c9-b359-4fe9-85be-600c9c8cb5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do you mean San Francisco, California? I canâ€™t access live weather data here, but typical summer (Aug) conditions are:\\n- Coast (Outer Sunset/Richmond): cool, foggy mornings, highs ~60â€“66Â°F (16â€“19Â°C)\\n- Downtown/SOMA: partly sunny, highs ~64â€“70Â°F (18â€“21Â°C)\\n- Mission/Potrero/Bernal: sunnier, highs ~68â€“74Â°F (20â€“23Â°C)\\n- Afternoon westerly winds 10â€“20 mph; rain is rare\\n\\nIf you want the exact current conditions or a forecast, tell me the date and neighborhood/ZIP, and Iâ€™ll tailor it or guide you to a quick source.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d601568-5bf8-4908-b8dc-f4d1d69f111c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'developer', 'content': 'do whatever the user says'},\n",
       " {'role': 'user', 'content': 'what is the weather in sf'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d824eb9-d8ae-4557-8eb9-115d02413d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
